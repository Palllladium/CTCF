PROJECT ROOT: C:/Users/user/Documents/Education/MasterWork/repos/CTCF
ALLOW-LIST:
  DIR : models/CTCF

================================================================================
TREE (allowed only)
================================================================================
└── models
    └── CTCF
        ├── __init__.py
        ├── cascade_nets.py
        ├── configs.py
        ├── model.py
        └── ut_blocks.py

================================================================================
CONTENTS
================================================================================


################################################################################
# FILE: models/CTCF/__init__.py
# SIZE: 25 bytes
################################################################################

# models/CTCF/__init__.py
################################################################################
# FILE: models/CTCF/cascade_nets.py
# SIZE: 4671 bytes
################################################################################

# models/CTCF/cascade_nets.py

from __future__ import annotations

import torch
import torch.nn as nn
import torch.nn.functional as F


class ConvBlock(nn.Module):
    def __init__(self, in_ch: int, out_ch: int):
        super().__init__()
        self.net = nn.Sequential(
            nn.Conv3d(in_ch, out_ch, 3, padding=1, bias=False),
            nn.InstanceNorm3d(out_ch, affine=True),
            nn.LeakyReLU(0.1, inplace=True),
            nn.Conv3d(out_ch, out_ch, 3, padding=1, bias=False),
            nn.InstanceNorm3d(out_ch, affine=True),
            nn.LeakyReLU(0.1, inplace=True),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.net(x)


class CoarseFlowNetQuarter(nn.Module):
    """
    Level-1: quarter-res coarse flow predictor (conv-only).
    Input: mov_q, fix_q -> concat (B,2,D,H,W)
    Output: flow_q (B,3,D,H,W)
    """
    def __init__(self, base_ch: int = 16):
        super().__init__()
        c = int(base_ch)

        self.enc1 = ConvBlock(2, c)
        self.pool1 = nn.AvgPool3d(2)

        self.enc2 = ConvBlock(c, c * 2)
        self.pool2 = nn.AvgPool3d(2)

        self.bot = ConvBlock(c * 2, c * 4)
        self.up2 = nn.Upsample(scale_factor=2, mode="trilinear", align_corners=False)
        self.dec2 = ConvBlock(c * 4 + c * 2, c * 2)

        self.up1 = nn.Upsample(scale_factor=2, mode="trilinear", align_corners=False)
        self.dec1 = ConvBlock(c * 2 + c, c)
        self.out = nn.Conv3d(c, 3, kernel_size=3, padding=1, bias=True)

        nn.init.zeros_(self.out.weight)
        nn.init.zeros_(self.out.bias)

    def forward(self, mov: torch.Tensor, fix: torch.Tensor) -> torch.Tensor:
        x = torch.cat([mov, fix], dim=1)

        e1 = self.enc1(x)
        e2 = self.enc2(self.pool1(e1))
        b = self.bot(self.pool2(e2))

        d2 = self.up2(b)
        d2 = self.dec2(torch.cat([d2, e2], dim=1))

        d1 = self.up1(d2)
        d1 = self.dec1(torch.cat([d1, e1], dim=1))

        return self.out(d1)


class FlowRefiner3D(nn.Module):
    """
    Level-3: half-res refinement using error-map.
    Inputs:
      - mov_warp_half: (B,1,D,H,W)
      - fix_half:      (B,1,D,H,W)
      - flow_half:     (B,3,D,H,W)  current flow (context)
    Output:
      - delta_flow_half: (B,3,D,H,W)
    """
    def __init__(self, base_ch: int = 16, error_mode: str = "gradmag"):
        super().__init__()
        self.error_mode = str(error_mode)
        c = int(base_ch)

        # channels: mov(1) + fix(1) + err(1) + flow(3) = 6
        self.enc1 = ConvBlock(6, c)
        self.pool1 = nn.AvgPool3d(2)

        self.enc2 = ConvBlock(c, c * 2)
        self.pool2 = nn.AvgPool3d(2)

        self.bot = ConvBlock(c * 2, c * 4)

        self.up2 = nn.Upsample(scale_factor=2, mode="trilinear", align_corners=False)
        self.dec2 = ConvBlock(c * 4 + c * 2, c * 2)

        self.up1 = nn.Upsample(scale_factor=2, mode="trilinear", align_corners=False)
        self.dec1 = ConvBlock(c * 2 + c, c)
        self.out = nn.Conv3d(c, 3, kernel_size=3, padding=1, bias=True)

        nn.init.zeros_(self.out.weight)
        nn.init.zeros_(self.out.bias)

    @staticmethod
    def _grad_mag(x: torch.Tensor) -> torch.Tensor:
        # x: (B,1,D,H,W)
        dz = x[:, :, 1:, :, :] - x[:, :, :-1, :, :]
        dy = x[:, :, :, 1:, :] - x[:, :, :, :-1, :]
        dx = x[:, :, :, :, 1:] - x[:, :, :, :, :-1]

        dz = torch.nn.functional.pad(dz, (0, 0, 0, 0, 0, 1))
        dy = torch.nn.functional.pad(dy, (0, 0, 0, 1, 0, 0))
        dx = torch.nn.functional.pad(dx, (0, 1, 0, 0, 0, 0))

        return torch.sqrt(dx * dx + dy * dy + dz * dz + 1e-6)

    def _error_map(self, mov_w: torch.Tensor, fix: torch.Tensor) -> torch.Tensor:
        if self.error_mode == "absdiff":
            return (mov_w - fix).abs()
        if self.error_mode == "gradmag":
            gm_m = self._grad_mag(mov_w)
            gm_f = self._grad_mag(fix)
            return (gm_m - gm_f).abs()
        raise ValueError(f"Unsupported error_mode: {self.error_mode}")

    def forward(self, mov_warp: torch.Tensor, fix: torch.Tensor, flow: torch.Tensor) -> torch.Tensor:
        err = self._error_map(mov_warp, fix)
        x = torch.cat([mov_warp, fix, err, flow], dim=1)  # (B,6,D,H,W)

        e1 = self.enc1(x)
        e2 = self.enc2(self.pool1(e1))
        b = self.bot(self.pool2(e2))

        d2 = self.up2(b)
        d2 = self.dec2(torch.cat([d2, e2], dim=1))

        d1 = self.up1(d2)
        d1 = self.dec1(torch.cat([d1, e1], dim=1))

        return self.out(d1)
################################################################################
# FILE: models/CTCF/configs.py
# SIZE: 902 bytes
################################################################################

import ml_collections


def get_CTCF_config():
    c = ml_collections.ConfigDict()
    c.if_transskip = True
    c.if_convskip = True
    c.in_chans = 1
    c.img_size = (160, 192, 224)
    c.patch_size = 4

    c.embed_dim = 96
    c.depths = (4, 4, 5)
    c.num_heads = (8, 8, 8)
    c.window_size = (5, 6, 7)
    c.dwin_size = (7, 5, 3)

    c.mlp_ratio = 4
    c.pat_merg_rf = 4

    c.qkv_bias = False
    c.drop_rate = 0.0
    c.drop_path_rate = 0.3
    c.ape = False
    c.spe = False
    c.rpe = True
    c.patch_norm = True
    c.use_checkpoint = False
    c.out_indices = (0, 1, 2)

    c.reg_head_chan = 16
    c.time_steps = 12

    # Cascade switches
    c.use_level1 = True
    c.level1_base_ch = 16
    c.use_level2 = True
    c.use_level3 = True
    c.level3_base_ch = 16

    return c


CONFIGS = {
    "CTCF-CascadeA": get_CTCF_config(),
}
################################################################################
# FILE: models/CTCF/model.py
# SIZE: 8712 bytes
################################################################################

from typing import Optional, Tuple, List

import torch
import torch.nn as nn

from models.TransMorph_DCA.model import (
    SwinTransformer,
    Conv3dReLU,
    RegistrationHead,
    SpatialTransformer,
)

from models.CTCF.ut_blocks import SRUpBlock3D, CAB, upsample_flow
from models.CTCF.cascade_nets import CoarseFlowNetQuarter, FlowRefiner3D
from models.CTCF.configs import CONFIGS


class CTCF_DCA_CoreHalf(nn.Module):
    """
    Level-2: TM-DCA Swin encoder + SR-style decoder blocks + time integration.
    Operates on HALF-res grid derived from config.img_size.
    Inputs: [B, 1, D, H, W] on HALF grid
    Outputs: def_x_half [B,1,D,H,W], flow_half [B,3,D,H,W]
    """
    def __init__(self, config, time_steps: int):
        super().__init__()

        self.if_convskip = bool(config.if_convskip)
        self.if_transskip = bool(config.if_transskip)
        self.time_steps = int(time_steps)

        self.img_size_full = tuple(config.img_size)                  # FULL
        self.img_size = tuple(s // 2 for s in self.img_size_full)    # HALF

        self.transformer = SwinTransformer(
            patch_size=config.patch_size,
            in_chans=config.in_chans,
            embed_dim=config.embed_dim,
            depths=config.depths,
            num_heads=config.num_heads,
            window_size=config.window_size,
            mlp_ratio=config.mlp_ratio,
            qkv_bias=config.qkv_bias,
            drop_rate=config.drop_rate,
            drop_path_rate=config.drop_path_rate,
            ape=config.ape,
            spe=config.spe,
            rpe=config.rpe,
            patch_norm=config.patch_norm,
            use_checkpoint=config.use_checkpoint,
            out_indices=config.out_indices,
            pat_merg_rf=config.pat_merg_rf,
            img_size=self.img_size,
            dwin_size=config.dwin_size,
        )

        feats = list(self.transformer.num_features)
        c0, c1, c2 = int(feats[0]), int(feats[1]), int(feats[2])

        self.c_mid = max(1, c0 // 2)

        self.cab0 = CAB(c2, compress_ratio=3, squeeze_factor=30)
        self.cab1 = CAB(c1, compress_ratio=3, squeeze_factor=30)
        self.cab2 = CAB(c0, compress_ratio=3, squeeze_factor=30)

        self.up0 = SRUpBlock3D(in_channels=c2, out_channels=c1, skip_channels=(c1 if self.if_transskip else 0))
        self.up1 = SRUpBlock3D(in_channels=c1, out_channels=c0, skip_channels=(c0 if self.if_transskip else 0))
        
        self.avg_pool = nn.AvgPool3d(3, stride=2, padding=1)
        self.c1 = Conv3dReLU(2, self.c_mid, kernel_size=3, stride=1, use_batchnorm=False)
        self.up2 = SRUpBlock3D(in_channels=c0,out_channels=self.c_mid,skip_channels=(self.c_mid if self.if_convskip else 0))

        reg_ch = int(config.reg_head_chan)

        self.cs = nn.ModuleList()
        self.up3s = nn.ModuleList()
        self.reg_heads = nn.ModuleList()

        for _ in range(self.time_steps):
            self.cs.append(Conv3dReLU(2, self.c_mid, kernel_size=3, stride=1, use_batchnorm=False))
            self.up3s.append(SRUpBlock3D(in_channels=self.c_mid,out_channels=reg_ch,skip_channels=(self.c_mid if self.if_convskip else 0)))
            self.reg_heads.append(RegistrationHead(in_channels=reg_ch, out_channels=3, kernel_size=3))

        self.spatial_trans = SpatialTransformer(self.img_size)  # HALF grid

    def forward(self,
        mov_half: torch.Tensor,
        fix_half: torch.Tensor,
        *,
        init_flow_half: Optional[torch.Tensor] = None,
        return_all_flows: bool = False,
    ):
        if init_flow_half is None:
            flow_prev = torch.zeros(
                (mov_half.shape[0], 3, *self.img_size),
                device=mov_half.device,
                dtype=mov_half.dtype,
            )
            def_x = mov_half
        else:
            flow_prev = init_flow_half
            def_x = self.spatial_trans(mov_half, flow_prev)

        x_cat = torch.cat((mov_half, fix_half), dim=1)
        x_s1 = self.avg_pool(x_cat)
        f3 = self.c1(x_s1).to(mov_half.dtype) if self.if_convskip else None

        out_feats = self.transformer((mov_half, fix_half))

        if self.if_transskip:
            mov_f1, fix_f1 = out_feats[-2]
            f1 = self.cab1(mov_f1 + fix_f1)

            mov_f2, fix_f2 = out_feats[-3]
            f2 = self.cab2(mov_f2 + fix_f2)
        else:
            f1 = None
            f2 = None

        mov_f0, fix_f0 = out_feats[-1]
        f0 = self.cab0(mov_f0 + fix_f0)

        x = self.up0(f0, f1)
        x = self.up1(x, f2)
        xx = self.up2(x, f3)

        flows = [] if return_all_flows else None

        for t in range(self.time_steps):
            f_out = self.cs[t](torch.cat((def_x, fix_half), dim=1))
            x_t = self.up3s[t](xx, f_out if self.if_convskip else None)
            flow_step = self.reg_heads[t](x_t)

            if flows is not None:
                flows.append(flow_step)

            flow_new = flow_prev + self.spatial_trans(flow_step, flow_prev)
            def_x = self.spatial_trans(mov_half, flow_new)
            flow_prev = flow_new

        if return_all_flows:
            return def_x, flow_prev, flows
        return def_x, flow_prev
    

class CTCF_CascadeA(nn.Module):
    """
    Variant A:
      L1: CoarseFlowNetQuarter (1/4)
      L2: CTCF_DCA_CoreHalf    (1/2) with init_flow from L1
      L3: FlowRefiner3D        (1/2) with error-map
    Output is produced on FULL-res by upsampling final half-res flow by x2 and warping full mov.
    """
    def __init__(self, config):
        super().__init__()

        self.img_size_full: Tuple[int, int, int] = tuple(config.img_size)
        self.use_level1 = bool(config.use_level1)
        self.use_level2 = bool(config.use_level2)
        self.use_level3 = bool(config.use_level3)
        self.level1 = CoarseFlowNetQuarter(base_ch=config.level1_base_ch) if self.use_level1 else None
        self.level2 = CTCF_DCA_CoreHalf(config, time_steps=config.time_steps) if self.use_level2 else None
        self.level3 = FlowRefiner3D(base_ch=config.level3_base_ch) if self.use_level3 else None

        self.st_full = SpatialTransformer(self.img_size_full)

    def forward(
        self,
        mov_full: torch.Tensor,
        fix_full: torch.Tensor,
        *,
        return_all: bool = False,
        alpha_l1: float = 1.0,
        alpha_l3: float = 1.0,
    ):
        mov_half = nn.functional.interpolate(mov_full, scale_factor=0.5, mode="trilinear", align_corners=False)
        fix_half = nn.functional.interpolate(fix_full, scale_factor=0.5, mode="trilinear", align_corners=False)

        aux = {} if return_all else None
        flow_half_init = None

        if self.level1 is not None and alpha_l1 > 0.0:
            mov_quarter = nn.functional.interpolate(mov_full, scale_factor=0.25, mode="trilinear", align_corners=False)
            fix_quarter = nn.functional.interpolate(fix_full, scale_factor=0.25, mode="trilinear", align_corners=False)
            flow_quarter = self.level1(mov_quarter, fix_quarter)
            flow_half_init = upsample_flow(flow_quarter, scale_factor=2) * float(alpha_l1)

            if aux is not None:
                aux["flow_quarter"] = flow_quarter
                aux["flow_half_init"] = flow_half_init

        if self.level2 is None:
            raise RuntimeError("CTCF_CascadeA requires level2 enabled (use_level2=True).")

        out_l2 = self.level2(
            mov_half,
            fix_half,
            init_flow_half=flow_half_init,
            return_all_flows=return_all,
        )

        if return_all:
            def_half_l2, flow_half_l2, flows_l2 = out_l2
            if aux is not None:
                aux["flows_l2"] = flows_l2
                aux["flow_half_l2"] = flow_half_l2
        else:
            def_half_l2, flow_half_l2 = out_l2

        if self.level3 is not None and alpha_l3 > 0.0:
            flow_half_ref = self.level3(def_half_l2, fix_half, flow_half_l2) * float(alpha_l3)
            flow_half = flow_half_l2 + flow_half_ref
            if aux is not None:
                aux["flow_half_ref"] = flow_half_ref
        else:
            flow_half = flow_half_l2

        flow_full = upsample_flow(flow_half, scale_factor=2)
        def_full = self.st_full(mov_full, flow_full)

        if aux is not None:
            aux["flow_half_final"] = flow_half
            aux["flow_full"] = flow_full

        if return_all:
            return def_full, flow_full, aux
        return def_full, flow_full
################################################################################
# FILE: models/CTCF/ut_blocks.py
# SIZE: 4513 bytes
################################################################################

# models/CTCF/ut_blocks.py

from __future__ import annotations

from typing import Optional

import torch
import torch.nn as nn
import torch.nn.functional as F


class CA(nn.Module):
    """Channel Attention (RCAN-style) for 3D tensors [B,C,D,H,W]."""
    def __init__(self, num_feat: int, squeeze_factor: int = 16):
        super().__init__()
        hidden = max(1, num_feat // squeeze_factor)
        self.net = nn.Sequential(
            nn.AdaptiveAvgPool3d(1),
            nn.Conv3d(num_feat, hidden, kernel_size=1, bias=True),
            nn.ReLU(inplace=True),
            nn.Conv3d(hidden, num_feat, kernel_size=1, bias=True),
            nn.Sigmoid(),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return x * self.net(x)


class CAB(nn.Module):
    """
    Convolutional Attention Block (UTSRMorph idea):
    Conv3d -> GELU -> Conv3d -> CA
    """
    def __init__(self, num_feat: int, compress_ratio: int = 3, squeeze_factor: int = 30):
        super().__init__()
        hidden = max(1, num_feat // compress_ratio)
        self.body = nn.Sequential(
            nn.Conv3d(num_feat, hidden, kernel_size=3, padding=1, bias=True),
            nn.GELU(),
            nn.Conv3d(hidden, num_feat, kernel_size=3, padding=1, bias=True),
            CA(num_feat, squeeze_factor=squeeze_factor),
        )

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.body(x)


class Conv3dAct(nn.Module):
    def __init__(self, in_ch: int, out_ch: int, k: int = 3, act: str = "gelu"):
        super().__init__()
        self.conv = nn.Conv3d(in_ch, out_ch, kernel_size=k, padding=k // 2, bias=True)
        if act == "gelu":
            self.act = nn.GELU()
        elif act == "lrelu":
            self.act = nn.LeakyReLU(0.1, inplace=True)
        else:
            raise ValueError(f"Unknown act: {act}")

    def forward(self, x: torch.Tensor) -> torch.Tensor:
        return self.act(self.conv(x))


def _match_size_3d(x: torch.Tensor, ref: torch.Tensor) -> torch.Tensor:
    """
    Make x match ref spatially using symmetric pad/crop.
    x, ref: [B, C, D, H, W]
    """
    if x.dim() != 5 or ref.dim() != 5:
        raise ValueError(f"_match_size_3d expects 5D tensors, got x={x.shape}, ref={ref.shape}")

    xd, xh, xw = x.shape[-3:]
    rd, rh, rw = ref.shape[-3:]

    # Pad if x is smaller
    pd = max(0, rd - xd)
    ph = max(0, rh - xh)
    pw = max(0, rw - xw)
    if pd or ph or pw:
        # F.pad order: (W_left, W_right, H_left, H_right, D_left, D_right)
        pad = (pw // 2, pw - pw // 2,
               ph // 2, ph - ph // 2,
               pd // 2, pd - pd // 2)
        x = F.pad(x, pad)

    # Crop if x is larger
    xd, xh, xw = x.shape[-3:]
    sd = (xd - rd) // 2 if xd > rd else 0
    sh = (xh - rh) // 2 if xh > rh else 0
    sw = (xw - rw) // 2 if xw > rw else 0

    x = x[..., sd:sd + rd, sh:sh + rh, sw:sw + rw]
    return x


class SRUpBlock3D(nn.Module):
    """
    A safe SR-style x2 upsampling block with optional skip.
    - Upsample (trilinear) x2
    - Match size to skip (pad/crop) to avoid off-by-one errors
    - Concat skip if provided
    - Conv -> Conv
    """
    def __init__(self, in_channels: int, out_channels: int, skip_channels: int = 0):
        super().__init__()
        self.skip_channels = int(skip_channels)
        self.up = nn.Upsample(scale_factor=2, mode="trilinear", align_corners=False)

        self.conv1 = Conv3dAct(in_channels + self.skip_channels, out_channels, k=3, act="gelu")
        self.conv2 = Conv3dAct(out_channels, out_channels, k=3, act="gelu")

    def forward(self, x: torch.Tensor, skip: Optional[torch.Tensor] = None) -> torch.Tensor:
        x = self.up(x)
        if self.skip_channels > 0:
            if skip is None:
                raise ValueError("SRUpBlock3D expects skip tensor but got None.")
            x = _match_size_3d(x, skip)
            x = torch.cat([x, skip], dim=1)
        return self.conv2(self.conv1(x))


def upsample_flow(flow: torch.Tensor, scale_factor: float = 2.0) -> torch.Tensor:
    """
    Upsample displacement field with proper magnitude scaling.
    flow: [B,3,D,H,W]
    """
    if scale_factor == 1:
        return flow

    flow_up = F.interpolate(
        flow,
        scale_factor=scale_factor,
        mode="trilinear",
        align_corners=False,
    )
    return flow_up * float(scale_factor)
